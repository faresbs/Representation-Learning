% (meta)
% Exercise contributed by Wesley Chung
% label: ch8 

\Exercise{
\label{ex:adam_moment}
In this question you will demonstrate that an estimate of the first moment of the gradient using an (exponential) running average is equivalent to using momentum, and is biased by a scaling factor. The goal of this question is for you to consider the relationship between different optimization schemes, and to practice noting and quantifying the effect (particularly in terms of bias/variance) of \textit{estimating} a quantity.

Let $\vg_t$ be an unbiased sample of gradient at time step $t$ and $\Delta\vtheta_t$ be the update to be made.
Initialize $\vv_0$ to be a vector of zeros.
\begin{enumerate}
\item For $t\geq1$, consider the following update rules:
    \begin{itemize}
      \item SGD with momentum:
        $$ \vv_t = \alpha \vv_{t-1} + \epsilon \vg_t \qquad \Delta\vtheta_t = -\vv_t $$
        where $\epsilon>0$ and $\alpha\in(0,1)$.
      \item SGD with running average of $\vg_t$:
        $$ \vv_t = \beta \vv_{t-1} + (1-\beta) \vg_t \qquad \Delta\vtheta_t = -\delta \vv_t $$
        where $\beta\in(0,1)$ and $\delta>0$. 
    \end{itemize} 
Express the two update rules recursively ($\Delta\vtheta_t$ as a function of $\Delta\vtheta_{t-1}$). 
Show that these two update rules are equivalent; i.e. express $(\alpha,\epsilon)$ as a function of $(\beta,\delta)$.

\item Unroll the running average update rule, i.e. express $\vv_t$ as a linear combination of $\vg_i$'s ($1\leq i\leq t$).

\item Assume $\vg_t$ has a stationary distribution independent of $t$. 
Show that the running average is biased, i.e. $\E[\vv_t]\neq\E[\vg_t]$. Propose a way to eliminate such a bias by rescaling $\vv_t$. 
  
\end{enumerate}}

\Answer{
${}$%placeholder
}

