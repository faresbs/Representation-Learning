% (meta)
% Exercise contributed by Aristide Baratin
% label: ch6

\Exercise{
\label{ex:finite_sample_uat}
Given $N \in \sZ^+$, we want to show that for any $f:\R^n \to \R^m$ and any sample set $\gS\subset \R^n$ of size $N$, there is a set of parameters for a two-layer network such that the output $y(\vx)$ matches $f(\vx)$ for all $\vx \in \gS$.
That is, we want to interpolate $f$ with $y$ on any finite set of samples $\gS$. 
\begin{enumerate}
\item Write the generic form of the function $y: \R^n \to \R^m$ defined by a 2-layer network with $N-1$ hidden units, with linear output and activation function $\phi$, in terms of its weights and biases $(\mW^{(1)}, \vb^{(1)})$ and $(\mW^{(2)}, \vb^{(2)})$.
\item In what follows, we will restrict $\mW^{(1)}$ to be $\mW^{(1)} = [\vw, \cdots, \vw]^T$ for some $\vw \in \R^n$ (so the rows of  $\mW^{(1)}$ are all the same).
Show that the interpolation problem on the sample set $\gS=\{\vx^{(1)}, \cdots \vx^{(N)}\} \subset \R^n$ can be reduced to solving a matrix equation: 
$\mM\tilde{\mW}^{(2)}=\mF$,
where $\tilde{\mW}^{(2)}$ and $\mF$ are both $N\times m$, given by
$$\tilde{\mW}^{(2)}=[\mW^{(2)}, \vb^{(2)}]^\top \qquad\qquad \mF=[f(\vx^{(1)}), \cdots, f(\vx^{(N)})]^\top$$
Express the $N \times N$ matrix $\mM$ in terms of $\vw$, $\vb^{(1)}$, $\phi$ and $\vx^{(i)}$.
\staritem {\bf Proof with Relu activation.} 
Assume $\vx^{(i)}$ are all distinct. 
Choose $\vw$ such that $\vw^\top \vx^{(i)}$ are also all distinct (Try to prove the existence of such a $\vw$, although this is not required for the assignment - See Assignment 0). 
Set $\vb^{(1)}_j = -\vw^\top \vx^{(j)} + \epsilon$, where $\epsilon >0$. 
Find a value of $\epsilon$ such that $\mM$ is triangular with non-zero diagonal elements.
Conclude.
(Hint: assume an ordering of $\vw^\top\vx^{(i)}$.)
\staritem {\bf Proof with sigmoid-like activations}. 
Assume $\phi$ is continuous, bounded, $\phi(-\infty)=0$ and $\phi(0)>0$.
Decompose $\vw$ as $\vw=\lambda\vu$. 
Set $\vb^{(1)}_j = -\lambda \vu^\top \vx^{(j)}$.
Fixing $\vu$, show that $\lim_{\lambda\to +\infty} {\mM}$ is triangular with non-zero diagonal elements. Conclude. 
(Note that doing so preserves the distinctness of $\vw^\top \vx^{(i)}$.)
\end{enumerate}
}

\Answer{
${}$%placeholder
Q.1
$$\mY = \mW^{(2)} [\phi(\mW^{(1)} \mX + \vb^{(1)})] + \vb^{(2)}$$
Q.2: Define the data matrix (pseudo-data matrix) and a pseudo-weight matrix as
$$
\tilde{\mat{X}}=
  \begin{bmatrix}
  \vx^{(1)}_1&\vx^{(2)}_1&\dots&\vx^{(N)}_1\\
  \vdots&\vdots&\dots&\vdots\\
  \vx^{(1)}_n&\vx^{(2)}_n&\dots&\vx^{(N)}_n\\
  1&1&\dots&1  
  \end{bmatrix},\;\;\;
  \tilde{\mat{W}}^{(1)}=
  \begin{bmatrix}
  \vw^{(1)}_{11}&\vw^{(1)}_{12}&\dots&\vw^{(1)}_{1n}&\vb^{(1)}_1\\
  \vw^{(1)}_{21}&\vw^{(1)}_{22}&\dots&\vw^{(1)}_{2n}&\vb^{(1)}_2\\
  \vdots&\vdots&\dots&\vdots&\vdots\\
 
  \vw^{(1)}_{N-1,1}&\vw^{(1)}_{N-1,2}&\dots&\vw^{(1)}_{N-1,n}&\vb^{(1)}_{N-1}
  \end{bmatrix}
$$
We define a new matrix $\mA$:
$$
\phi(\mW^{(1)} \mX + \vb^{(1)})=\phi(\tilde{\mW}^{(1)} \tilde{\mX})=\mA_{N-1\times N}
$$
And we can write:
$$\mY_{m\times N} = \mW^{(2)}_{m\times N-1} [\mA]_{N-1\times N} + \vb^{(2)}=
[\mW^{(2)},\vb^{(2)}]_{m\times N}
\begin{bmatrix}
    &\mA\\ &\m1^T
\end{bmatrix}
_{N\times N}
$$
Transposing the above we have:
$$[\mY^T]_{N\times m}=[\mM]_{N\times N}[\tilde{\mW}^{(2)}]_{N\times m}$$
It is easily seen that $\mM$ is given by:
$$
\mM=\phi
  \begin{bmatrix}
  \vw^{T}\vx^{(1)}+\vb^{(1)}_1&
  \vw^{T}\vx^{(1)}+\vb^{(1)}_2&
  \dots&
  \vw^{T}\vx^{(1)}+\vb^{(1)}_{N-1}&1\\
  \vw^{T}\vx^{(2)}+\vb^{(1)}_1&
  \vw^{T}\vx^{(2)}+\vb^{(1)}_2&
  \dots&
  \vw^{T}\vx^{(2)}+\vb^{(1)}_{N-1}&1\\
  \vdots&\vdots&\dots&\vdots&\vdots\\
  \vw^{T}\vx^{(N)}+\vb^{(1)}_1&
  \vw^{T}\vx^{(N)}+\vb^{(1)}_2&
  \dots&
  \vw^{T}\vx^{(N)}+\vb^{(1)}_{N-1}&1
  \end{bmatrix}
  $$
Q.3
Given the choice $\vb^{(1)}_j = -\vw^\top \vx^{(j)} + \epsilon$, where $\epsilon >0$, this matrix can be written as 
$$
\mM=\phi
  \begin{bmatrix}
  \epsilon&
  \vw^{T}(\vx^{(1)}-\vx^{(2)})+\epsilon&
  \dots&
  \vw^{T}(\vx^{(1)}-\vx^{(N-1)})+\epsilon&1\\
  \vw^{T}(\vx^{(2)}-\vx^{(1)})+\epsilon&
  \epsilon&
  \dots&
  \vw^{T}(\vx^{(2)}-\vx^{(N-1)})+\epsilon&1\\
  \vdots&\vdots&\dots&\vdots&\vdots\\
  \vw^{T}(\vx^{(N)}-\vx^{(1)})+\epsilon&
  \vw^{T}(\vx^{(N)}-\vx^{(2)})+\epsilon&
  \dots&
  \vw^{T}(\vx^{(N)}-\vx^{(N-1)})+\epsilon&1
  \end{bmatrix}
  $$
It is easily seen that if $\phi$ is Relu and if we choose the following ordering 
$$
\vw^{T}\vx^{(1)}>\vw^{T}\vx^{(2)}>\dots>
\vw^{T}\vx^{(N)}
$$
the matrix $\mM$ can be upper triangular as long as we choose $0<\epsilon<\vw^{T}\vx^{(N)}$.\\
Q.4: If $\phi$ is the given sigmoid like activation function and if we choose $\vb^{(1)}_j = -\lambda\vu^\top \vx^{(j)}$
$$
\mM=
  \begin{bmatrix}
  \phi(0)&
  \phi(\lambda\vu^{T}(\vx^{(1)}-\vx^{(2)}))&
  \dots&
  \phi(\lambda\vu^{T}(\vx^{(1)}-\vx^{(N-1)}))&1\\
  \phi(\lambda\vu^{T}(\vx^{(2)}-\vx^{(1)}))&
  \phi(0)&
  \dots&
  \phi(\lambda\vu^{T}(\vx^{(2)}-\vx^{(N-1)}))&1\\
  \vdots&\vdots&\dots&\vdots&\vdots\\
  \phi(\lambda\vu^{T}(\vx^{(N)}-\vx^{(1)}))&
  \phi(\vu^{T}(\vx^{(N)}-\vx^{(2)}))&
  \dots&
  \phi(\lambda\vu^{T}(\vx^{(N)}-\vx^{(N-1)}))&1
  \end{bmatrix}
  $$
  The diagonal entries of this matrix are $\phi(0)>0$ and 1 i.e. they are non-zero. Most of the upper and lower non-diagonal entries have opposite signs. For fixed $\vu$, the sign of these entries, all of which are of the form $\lambda\vu^{T}(\vx^{(i)}-\vx^{(j)})$ depends on the difference $\vx^{(i)}-\vx^{(j)}$. From the structure of the matrix it is clear that if we choose these differences to be positive above the main diagonal and negative below it, we will have
  $$
  \lambda\vu^{T}(\vx^{(i)}-\vx^{(j)})>0,\;\; \forall   i>j
  $$
  $$
  \lambda\vu^{T}(\vx^{(i)}-\vx^{(j)})<0,\;\; \forall   i<j
  $$
  Since $\phi(-\infty)=0$ and
  $\phi(x)$ is bounded, we can assume that \phi(+\infty)=c$ and $\phi(0)=a$ for some constants $a$ and $c$. 
  $$
\lim_{\lambda\rightarrow {+\infty}}\mM=
  \begin{bmatrix}
  \phi(0)&\phi(+\infty)&\dots&\phi(+\infty)&1\\
  \phi(-\infty)&\phi(0)&\dots&\phi(+\infty)&1\\
  \vdots&\vdots&\dots&\vdots&\vdots\\
  \phi(-\infty)&\phi(-\infty)&\dots&\phi(0)&1\\
  \phi(-\infty)&\phi(-\infty)&\dots&\phi(-\infty)&1
  \end{bmatrix}
  =
  \begin{bmatrix}
  a&c&\dots&c&1\\
  0&a&\dots&c&1\\
  \vdots&\vdots&\dots&\vdots&\vdots\\
  0&0&\dots&a&1\\
  0&0&\dots&0&1
  \end{bmatrix}
  $$
}
