\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}
\usepackage{hyperref}
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}

\input{math_commands.tex}

%\setlength{\parskip}{\baselineskip}
%\setlength{\parindent}{0pt}

\usetikzlibrary{automata,positioning}

%
% Basic Document Settings
%

\setlength{\parindent}{0cm}
\addtolength{\oddsidemargin}{-2cm}
\addtolength{\evensidemargin}{-2cm}
\setlength{\textwidth}{17.78cm}
\addtolength{\topmargin}{-2.25cm}
\setlength{\textheight}{24.24cm}
\addtolength{\parskip}{5mm}

\pagestyle{fancy}
%\lhead{\hmwkAuthorName}
\lhead{\hmwkClass\ (\hmwkClassInstructor) \#\hmwkNumber}
\rhead{\firstxmark}
\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{0pt}

%
% Create Problem Sections
%

\newcommand{\enterProblemHeader}[1]{
    \nobreak\extramarks{}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
}

\newcommand{\exitProblemHeader}[1]{
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \stepcounter{#1}
    \nobreak\extramarks{Problem \arabic{#1}}{}\nobreak{}
}

\setcounter{secnumdepth}{0}
\newcounter{partCounter}
\newcounter{homeworkProblemCounter}
\setcounter{homeworkProblemCounter}{1}
\nobreak\extramarks{Problem \arabic{homeworkProblemCounter}}{}\nobreak{}

%
% Homework Problem Environment
%
% This environment takes an optional argument. When given, it will adjust the
% problem counter. This is useful for when the problems given for your
% assignment aren't sequential. See the last 3 problems of this template for an
% example.
%
\newenvironment{homeworkProblem}[1][-1]{
    \ifnum#1>0
        \setcounter{homeworkProblemCounter}{#1}
    \fi
    \section{Problème \arabic{homeworkProblemCounter}}
    \setcounter{partCounter}{1}
    \enterProblemHeader{homeworkProblemCounter}
}{
    \exitProblemHeader{homeworkProblemCounter}
}

%
% Homework Details
%   - Title
%   - Due date
%   - Class
%   - Section/Time
%   - Instructor
%   - Author
%

\newcommand{\hmwkTitle}{Homework \hmwkNumber}
\newcommand{\hmwkNumber}{1}
\newcommand{\hmwkDueDate}{February 12, 2018 at 23h30}
\newcommand{\hmwkClass}{IFT6135H18 - Representation Learning}
\newcommand{\hmwkClassInstructor}{Aaron Courville}


%
% Title Page
%

\title{
    \vspace{0in}
    \textmd{\textbf{\hmwkClass}}\\
    \hmwkTitle \ - Programming Part\\
    \normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
    \vspace{0.1in}\large{Instructor: \textit{\hmwkClassInstructor\\}} 
    \vspace{0in}
}

%\author{\hmwkAuthorName}
%\date{}

\renewcommand{\part}[1]{\textbf{\large Part \Alph{partCounter}}\stepcounter{partCounter}\\}



%
% Various Helper Commands
%

% Useful for algorithms
\newcommand{\alg}[1]{\textsc{\bfseries \footnotesize #1}}
% For derivatives
\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}
% Integral dx
\newcommand{\dx}{\mathrm{d}x}
% Alias for the Solution section header
\newcommand{\solution}{\textbf{\large Solution}}
% Probability commands: Expectation, Variance, Covariance, Bias

\newcommand{\Bias}{\mathrm{Bias}}
\newcommand{\N}{\mathcal{N}}

\begin{document}

\fancyhead{}
\fancyfoot{}

\fancyhead[L]{
  \begin{tabular}[b]{l}
    IFT6135-H2019  \\
    Prof: Aaron Courville \\
  \end{tabular}
}
\fancyhead[R]{
  \begin{tabular}[b]{r}
    Devoir 1, Partie pratique  \\
    Multilayer Perceptrons and Convolutional Neural Networks \\
  \end{tabular}
}

{\bf A rendre le: 16 février 2019}

\vspace{-0.5cm}
\underline{Instructions}
%Laissez des traces de votre démarche pour toutes les questions! \\
\renewcommand{\labelitemi}{\textbullet}
\begin{itemize}
\item \emph{Montrez les traces de votre travail pour toutes les questions!}
\item \emph{Il faut soumettre votre code et votre rapport (pdf) via la page Gradescope du cours. Si vous utilisez le Jupyter Notebook, vous devez l'exporter en pdf, et le soumettre via Gradescope.}
\item \emph{Votre code doit être dans un dépôt Github (\textit{repository}). Vous devez inclure le lien du dépôt dans votre rapport!}
\end{itemize}
%\maketitle
\begin{homeworkProblem}
    Dans ce problème, nous allons construire un perceptron multicouche (\textit{multilayer perceptron}, MLP) et l'entraîner sur l'ensemble de données de chiffres manuscrits \href{http://yann.lecun.com/exdb/mnist/}{MNIST}
    \footnote{\url{http://yann.lecun.com/exdb/mnist/} - Utiliser la séparation standard entrainement/validation/test similaire à celle donnée \href{https://github.com/CW-Huang/IFT6135H18_assignment}{ici}\footnote{\url{https://github.com/CW-Huang/IFT6135H18_assignment}}.}. 
    
  \vspace{0.1cm}  
\paragraph{Construction du modele}
Considérons un MLP à deux couches cachées, avec un nombre de neurones $h^{1}$ et $h^{2}$ respectivement. Pour l'ensemble de données MNIST, le nombre de \textit{features} des données d'entrée est $h^{0} = 784$. La sortie du reseau de neurones est parametrisée par la fonction softmax avec $h^3=10$ classes


\begin{enumerate}
\item Construisez un MLP et choisissez les valeurs de $h^{1}$ et $h^{2}$ telles que le nombre total de parametres du reseau (en prenant en compte les biais) soit dans l'intervalle [0.5M, 1.0M].
\item Implémentez la propagation avant et arrière (\textit{forward and backward propagation}) du MLP, avec numpy, sans utiliser aucune librairie d'apprentissage profond qui permet de faire la différentiation automatique. Utilisez la structure de classe donnée \href{https://github.com/CW-Huang/IFT6135H19_assignment/blob/master/assignment1.ipynb}{ici} \footnote{\url{https://github.com/CW-Huang/IFT6135H19_assignment/blob/master/assignment1.ipynb}}. 
\item Entraînez le MLP en utilisant l'entropie croisée (\textit{cross entropy}) comme fonction de coût. Minimisez cette fonction de coût pour optimiser les paramètres du model en utilisant \textit{la descente de gradient stochastique} (SGD).
 
\end{enumerate}  

Pour les questions suivantes, précisez l'\textit{architecture du modèle} (le nombre de neurones dans chaque couche, et le nombre total de parametres), la \textit{fonction d'activation} utilisée, le \textit{taux d'apprentissage} (\textit{learning rate}), et la \textit{taille des mini-batch}.
  
\paragraph{Initialisation}
Dans cette partie du problème, on considère différentes valeurs initiales pour les poids du reseau. Les biais sont tous égaux à zéro. On considère les initialisations suivantes pour les poids:

  \begin{itemize}
  \item \textbf{Zéro}: Tous les poids sont initialisés a zéro.
  \item \textbf{Normale}: Les valeurs des poids sont tirées d'une loi normale standard: $w_{i,j}\sim \N(w_{i,j};0,1)$.
  \item \textbf{Glorot}: Les valeurs des poids sont tirées d'une distribution uniforme: $w^{l}_{i,j}\sim \mathcal{U}(w^l_{i,j};-d^l,d^l)$ où $d^l=\sqrt{\frac{6}{h^{l-1}+h^{l}}}$.
\end{itemize}
 
\begin{enumerate}
  \item Entraînez le modèle pendant 10 époques (\textit{epochs}) \footnote{une époque correspond à un passage sur la totalitée de l'ensemble d'entraînement} en utilisant les méthodes d'initialisation précédentes, et sauvegardez le coût moyen mesuré sur l'ensemble d'entraînement à la fin de chaque époque (vous devriez donc avoir 10 valeurs pour chaque schéma initialisation).
  \item Comparez les trois schémas d'initialisation en traçant la courbe des coûts en fonction de la durée d'entraînement (époque). Commentez vos résultats obtenus. 
  \end{enumerate}
  
 \paragraph{Optimisation des hyper-paramètres}
 Dorénavant, utilisez l'initialisation de Glorot. 

\begin{enumerate}
	\item Trouvez une combinaison d'hyper-paramètres (architecture du réseau, taux d'apprentissage, fonction d'activation, etc.) telle que la précision moyenne (\textit{accuracy}) de classifications sur l'ensemble de validation ($r^{(valid)}$) soit d'au moins 97\%. 
	\item Reportez les hyper-paramètres que vous avez testés, et les $r^{(valid)}$ correspondants.
\end{enumerate}
  
   

  \paragraph{Validation des gradients en utilisant les différences finies}
  L'approximation par différences finies de la dérivée d'une fonction scalaire
  $x \in \R \mapsto f(x) \in \R$, avec une précision $\epsilon$, est définie par $\frac{f(x + \epsilon) - f(x - \epsilon)}{2\epsilon}$. Considérez les poids de la première couche du MLP que vous avez construit a la première question, comme un vector $\theta = (\theta_1, \dots, \theta_m)$. On s'intéresse à l'approximation du gradient de la fonction coût $L$, évaluée en utilisant \textbf{une seule} image de l'ensemble d'entraînement, par rapport à $\theta_{1:p}$, les $p = \min(10, m)$ premiers éléments de $\theta$, en utilisant les différences finies.
  
  \begin{enumerate}
  \item Évaluez l'approximation des gradients par différences finies $\nabla^N \in \R^p$ en utilisant $\epsilon = \frac{1}{N}$ pour différentes valeurs de $N$ $$\nabla^N_i = \frac{L(\theta_1, \dots, \theta_{i-1}, \theta_i + \epsilon, \theta_{i+1}, \dots, \theta_p) - L(\theta_1, \dots, \theta_{i-1}, \theta_i - \epsilon, \theta_{i+1}, \dots, \theta_p)}{2 \epsilon}$$ 
  Utilisez au moins 5 valeurs de $N$ parmi $\{k  10^i: \ i \in \{0, \dots, 5\}, \ k \in \{1, 5\}\} $. Tracez la courbe de la différence maximale entre le vrai gradient et l'approximation par différences finies en fonction de $N$.
  
 
  \item  Tracez la courbe de la différence maximale entre le vrai gradient et l'approximation par différences finies ($\max_{1 \leq i \leq p} |\nabla^N_i - \frac{\partial L}{\partial \theta_i}| $) en fonction de $N$. Commentez le résultat. 
\end{enumerate}

\end{homeworkProblem}
  
\begin{homeworkProblem}
    \textit{Réseaux neuronaux à convolution}: Plusieurs techniques correspondent à l'incorporation de connaissances à priori sur la structure des données dans la paramétrisation du modèle. Par exemple, la convolution est adéquate pour le traitement d'images.

  %\vspace{-15pt}
  Dans cette partie du devoir, nous allons entraîner un réseau neuronal à convolution (CNN) sur l'ensemble de donnée MNIST pendant 10 époques. Vous pouvez utiliser une librairie d'apprentissage profond comme Pytorch ou Tensorflow. Tracez les erreurs sur les ensembles d'entraînement et de validation à la fin de chaque époque.
  \begin{enumerate}
  \item Trouvez une architecture CNN avec environ le même nombre de paramètres que le MLP entraîné au Problème 1. Décrivez l'architecture.
  \item Comparez les performances du CNN à celles obtenues par le MLP. Commentez vos observations.
\end{enumerate}
Vous pouvez vous inspirer de l'architecture utilisée
\href{https://github.com/MaximumEntropy/welcome_tutorials/tree/pytorch/pytorch} {ici}\footnote{\url{https://github.com/MaximumEntropy/welcome_tutorials/tree/pytorch/pytorch}}.
\end{homeworkProblem}
%------------------------
%    Question 2:   
%------------------------
\begin{homeworkProblem}
Dogs vs. Cats est une competition InclassKaggle pour la classification d'images. En utilisant ce que vous avez appris en cours et dans les problèmes précédents, essayez d'entraîner le meilleur classifieur CNN (réseau de neurones à convolution) pour cette tâche. Utilisez le lien \href{https://www.kaggle.com/c/ift6135h19}{suivant}\footnote{\url{https://www.kaggle.com/c/ift6135h19}} pour télécharger les données et accéder à la compétition. Assurez-vous de bien lire la description et les règles.
\begin{itemize}
\item Les données sont déjà traitées et prêtes à être utilisées, mais vous pouvez pré-traiter plus vos données (\textit{preprocessing}) si vous le souhaitez. Vous pouvez par exemple faire votre propre recadrage (\textit{cropping}). Toute étape de traitement supplémentaire doit être mentionnée dans votre rapport. Vous ne pouvez pas utiliser de sources de données externes, mais vous pouvez utiliser les techniques d'augmentation de données usuelles (assurez-vous de les mentionner dans votre rapport). Vous êtes responsables de la division de l'ensemble d'entraînement en un ensemble d'entrainement et de validation.
\item En plus de vos soumissions Kaggle, on vous demande de soumettre votre code sur Gradescope, avec votre rapport. Nous allons faire tourner votre code et nous assurer qu'on peut recréer votre soumission.
\item Vous ne pouvez pas utiliser de techniques pas encore introduites en cours, directement des librairies d'apprentissage profond, comme les couches BatchNorm/WeightNorm/LayerNorm, les techniques de régularisation (comme Dropout), ou les optimiseurs comme ADAM ou SGD avec moment, ``sauf si vous les implémentez vous-mêmes''. 
\item Ce problème à pour but de vous donner une chance de jouer avec les méthodes vues en classe et les appliquer a un problème de classification réel. Montrez toutes les traces de ce que vous avez essayé (même ce qui n'a pas donné des scores élevés).
\item Votre note sera une combinaison du score de précision (\textit{accuracy}) obtenu sur la partie privée du classement (plus de détails sur Kaggle), et la qualité de votre rapport. Votre rapport doit inclure les réponses aux questions suivantes:
\end{itemize}

\textbf{Important: La date limite pour la soumission Kaggle est 1 jour avant celle du devoir.}
\begin{enumerate}
\item Décrivez l'architecture (nombre de couches, tailles des filtres de convolutions, couches de \textit{pooling}, etc.). Reportez le nombre total de paramètres. Vous pouvez vous inspirer de certaines architectures récentes, comme le réseau VGG, pour améliorer les performances.
\item Tracez les courbes de l'erreur sur l'ensemble d'entraînement et l'ensemble de validation, en plus des courbes de la fonction coût sur les deux ensembles. Commentez. Quelles techniques (que vous n'avez pas implémentées) pourraient être utiles pour améliorer les performances du modèle. Commentez les résultats obtenus sur l'ensemble de validation. Est-ce qu'ils se comparent à ceux obtenus sur l'ensemble de test (que vous pouvez obtenir sur Kaggle seulement).

\item Comparez différentes configurations d'hyperparamètres. Reportez les performances finales sur l'ensemble de validation. En plus des resultats quantitatifs, inclure des analyses visuelles, comme les \textit{feature maps} ou les filtres de convolution. Vous pouvez aussi montrer des exemples d'images qui (a) sont mal classifiées avec grande confidence et (b) résultent en des probabilités d'à peu près $0.5$ d'appartenir aux deux classes. Expliquez vos observations, et/ou suggérez des possibles pistes d'amélioration.

\end{enumerate}


\end{homeworkProblem}




\end{document}